{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Building your LSTM\n",
    "# batch_first=True causes input/output tensors to be of shape\n",
    "# (batch_dim, seq_dim, feature_dim)\n",
    "# lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first = True, bidirectional = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_features: size of each input sample\n",
    "# out_features: size of each output sample\n",
    "mlp=nn.Linear(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(20,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data=torch.chunk(x,chunks=4,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(10, 20, num_layers=2)\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2,batch_first = False)\n",
    "print(rnn)\n",
    "#batch_first = False;(seq_len,batch_size,dim)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(10, 20, num_layers=4, batch_first=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "input_size – The number of expected features in the input x\n",
    "\n",
    "hidden_size – The number of features in the hidden state h\n",
    "\n",
    "num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
    "'''\n",
    "rnn = nn.LSTM(10, 20, 4,batch_first = True)\n",
    "print(rnn)\n",
    "#batch_first = True;(batch_size,seq_len,dim)\n",
    "input = torch.randn( 3,5, 10)\n",
    "#(layers_size,batch_size,hidden_dim)\n",
    "h0 = torch.randn(4,3, 20)\n",
    "c0 = torch.randn(4,3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(10, 20, num_layers=4, batch_first=True, bidirectional=True)\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 4,batch_first = True,bidirectional = True)\n",
    "print(rnn)\n",
    "#batch_first = True;(batch_size,seq_len,feature_dim)\n",
    "input = torch.randn( 3,5, 10)\n",
    "#(layers_size,batch_size,hidden_dim)\n",
    "h0 = torch.randn(4,3, 20)\n",
    "c0 = torch.randn(4,3, 20)\n",
    "h20=torch.cat([h0,h0],dim = 0)\n",
    "c20=torch.cat([c0,c0],dim = 0)\n",
    "output, (hn, cn) = rnn(input, (h20, c20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 40])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最后一层的两个维度拼接到一起了\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LSTM输入: input, (h_0, c_0)\n",
    "\n",
    "input (seq_len, batch, input_size): 包含输入序列特征的Tensor。也可以是packed variable ，详见 [pack_padded_sequence](#torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False[source])\n",
    "\n",
    "h_0 (num_layers * num_directions, batch, hidden_size):保存着batch中每个元素的初始化隐状态的Tensor\n",
    "\n",
    "c_0 (num_layers * num_directions, batch, hidden_size): 保存着batch中每个元素的初始化细胞状态的Tensor\n",
    "\n",
    "LSTM输出 output, (h_n, c_n)\n",
    "\n",
    "output (seq_len, batch, hidden_size * num_directions): 保存RNN最后一层的输出的Tensor。 如果输入是torch.nn.utils.rnn.PackedSequence，那么输出也是torch.nn.utils.rnn.PackedSequence。\n",
    "\n",
    "h_n (num_layers * num_directions, batch, hidden_size): Tensor，保存着RNN最后一个时间步的隐状态。\n",
    "\n",
    "c_n (num_layers * num_directions, batch, hidden_size): Tensor，保存着RNN最后一个时间步的细胞状态。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand单个维度进行扩展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x.expand(2, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
       "        [1, 2, 3, 1, 2, 3, 1, 2, 3]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x.repeat(2,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0039,  0.2878, -0.3892,  0.5604]]],\n",
       "\n",
       "\n",
       "        [[[-0.6791,  0.6856,  0.0732,  0.0825]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 1, 1, 4)\n",
    "x.shape\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0039,  0.2878, -0.3892,  0.5604],\n",
       "          [ 1.0039,  0.2878, -0.3892,  0.5604],\n",
       "          [ 1.0039,  0.2878, -0.3892,  0.5604]],\n",
       "\n",
       "         [[ 1.0039,  0.2878, -0.3892,  0.5604],\n",
       "          [ 1.0039,  0.2878, -0.3892,  0.5604],\n",
       "          [ 1.0039,  0.2878, -0.3892,  0.5604]]],\n",
       "\n",
       "\n",
       "        [[[-0.6791,  0.6856,  0.0732,  0.0825],\n",
       "          [-0.6791,  0.6856,  0.0732,  0.0825],\n",
       "          [-0.6791,  0.6856,  0.0732,  0.0825]],\n",
       "\n",
       "         [[-0.6791,  0.6856,  0.0732,  0.0825],\n",
       "          [-0.6791,  0.6856,  0.0732,  0.0825],\n",
       "          [-0.6791,  0.6856,  0.0732,  0.0825]]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.expand(-1, 2, 3, -1)\n",
    "# .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
